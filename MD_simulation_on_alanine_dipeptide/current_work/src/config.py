import copy, pickle, re, os, time, subprocess, datetime, itertools, sys, abc, argparse
from scipy import io as sciio
import numpy as np, pandas as pd, seaborn as sns
from numpy.testing import assert_almost_equal
from math import *
from pybrain.structure import *
from pybrain.structure.modules.circularlayer import *
from pybrain.supervised.trainers import BackpropTrainer
from pybrain.datasets.supervised import SupervisedDataSet
from pybrain.structure.connections.shared import MotherConnection,SharedFullConnection
from pybrain.structure.moduleslice import ModuleSlice
import matplotlib.pyplot as plt
from sklearn.neighbors import RadiusNeighborsRegressor
import matplotlib
from Bio import PDB
from sklearn.metrics import mean_squared_error
from sklearn import linear_model
from MDAnalysis import Universe
from MDAnalysis.analysis.align import *
from MDAnalysis.analysis.rms import rmsd
from MDAnalysis.analysis.distances import distance_array

'''This is the configuration file for all Python code in this directory,
it configures all default values/global parameters for constructors/functions
'''

#######################################################################
############   some global variables and helper functions  ############
#######################################################################

layer_type_to_name_mapping = {TanhLayer: "Tanh", CircularLayer: "Circular", LinearLayer: "Linear", ReluLayer: "Relu"}
CONFIG_30 = "Trp_cage"     # the type of molecule we are studying
WARNING_INFO = "Comment out this line to continue."

def get_mol_param(parameter_list, molecule_name=CONFIG_30):   # get molecule specific parameter using a parameter list
    if molecule_name == "Alanine_dipeptide": return parameter_list[0]
    elif molecule_name == "Trp_cage": return parameter_list[1]
    elif molecule_name == "Src_kinase": return parameter_list[2]
    elif molecule_name == "BetaHairpin": return parameter_list[3]
    else: raise Exception("molecule not defined!")

def get_index_list_with_selection_statement(pdb_file, atom_selection_statement):
    return (Universe(pdb_file).select_atoms(atom_selection_statement).indices + 1).tolist()

#######################################################################
##################   configurations  ##################################
#######################################################################

CONFIG_45 = 'keras'                         # training backend: "pybrain", "keras"
CONFIG_48 = 'Cartesian'           # input data type
CONFIG_76 = 'Cartesian'           # output data type
temp_CONFIG_75_1 = np.ones(360); temp_CONFIG_75_1[3:24] = 4.0; temp_CONFIG_75_1[180 + 3: 180 + 24] = 4.0; temp_CONFIG_75_1 /= 4.0
CONFIG_75 = get_mol_param([None, None, None, None, None])      # weights for the expected output (equivalent to modifying error functions)
CONFIG_52 = 64                # number of copies we generate for data augmentation
CONFIG_58 = False              # use representative points for training (generated by clustering)
CONFIG_59 = 500               # number of representative points

CONFIG_49 = get_mol_param([5.0, 20.0, 40.0, 20.0, 20.0]) # scaling factor for output for Cartesian coordinates
CONFIG_1 = ['../target/' + CONFIG_30] # list of directories that contains all coordinates files

CONFIG_57 = [
    [2,5,7,9,15,17,19],
    get_index_list_with_selection_statement('../resources/1l2y.pdb', 'backbone and not name O'),
    # get_index_list_with_selection_statement('../resources/2src.pdb', 'backbone and not name O'),
    # get_index_list_with_selection_statement('../resources/2src.pdb',
    #                                         '(resid 144:170 or resid 44:58) and not name H*'),
    [ 694,  704,  714,  719,  729,  734,  744,  760,  764,  771,  783,
        793,  800,  810,  815,  825,  835,  842,  858,  869,  875,  891,
        897,  913,  919,  926, 2311, 2321, 2328, 2333, 2349, 2353, 2360,
       2367, 2379, 2389, 2404, 2413, 2420, 2432, 2451, 2461, 2466, 2473,
       2478, 2485, 2492, 2502, 2507, 2523, 2528, 2542, 2552, 2567, 2576,
       2586, 2593, 2600, 2610, 2626, 2632, 2648, 2651, 2661, 2666, 2685,
       2701, 2707, 2714, 2731],
    get_index_list_with_selection_statement('../resources/BetaHairpin.pdb', 'backbone and not name O'),
    list(range(1, 25))
]                                          # index list of atoms for training and biased simulations
if CONFIG_76 == 'pairwise_distance' or CONFIG_76 == 'combined':
    CONFIG_73 = get_mol_param([None, 'name CA',
                               '(resid 144:170 or resid 44:58) and name CA', None
                               ])                         # atom selection for calculating pairwise distances, used only when it is in 'pairwise_distance' mode

CONFIG_17 = [TanhLayer, TanhLayer, TanhLayer]  # types of hidden layers
CONFIG_78 = LinearLayer                    # output layer type
CONFIG_79 = False                         # determine dimensionality of input/output of autoencoder automatically
CONFIG_2 = 1     # training data interval
if CONFIG_45 == 'pybrain':
    raise Exception("Warning: PyBrain is no longer supported!  " + WARNING_INFO)
elif CONFIG_45 == 'keras':
    if CONFIG_76 == 'cossin':
        CONFIG_4 = get_mol_param([
            [.5,.4,0, True, [0.001, 0.001, 0.001, 0.001]] if CONFIG_17[1] == CircularLayer else [0.3, 0.9, 0, True, [0.00, 0.1, 0.00, 0.00]],
            None, None, None
        ])
    elif CONFIG_76 == 'Cartesian' or CONFIG_76 == 'combined':
        CONFIG_4 = get_mol_param([
            [.5, 0.5, 0, True, [0.00, 0.0000, 0.00, 0.00]],
            [0.3, 0.9, 0, True, [0.00, 0.0000, 0.00, 0.00]],
            [0.3, 0.9, 0, True, [0.00, 0.0000, 0.00, 0.00]],
            [0.3, 0.9, 0, True, [0.00, 0.0000, 0.00, 0.00]],
            [0.3, 0.9, 0, True, [0.00, 0.0000, 0.00, 0.00]],
            ])   # [learning rates, momentum, learning rate decay, nesterov, regularization coeff]
    elif CONFIG_76 == 'pairwise_distance':
        CONFIG_4 = get_mol_param([
            None, [1.5, 0.9, 0, True, [0.00, 0.0000, 0.00, 0.00]], None, None
        ])
    else: raise Exception('error')
else:
    raise Exception('training backend not implemented')

CONFIG_5 = 200                   # max number of training epochs
CONFIG_6 = None                # filename to save this network
CONFIG_36 = 2                  #   dimensionality
if CONFIG_17[1] == CircularLayer:
    CONFIG_37 = 2 * CONFIG_36              # number of nodes in bottleneck layer
elif CONFIG_17[1] == TanhLayer or CONFIG_17[1] == ReluLayer:
    CONFIG_37 = CONFIG_36
else:
    raise Exception('Layer not defined')

CONFIG_71 = False                  # use mixed error function
CONFIG_62 = get_mol_param([
    ['../resources/alanine_dipeptide.pdb', '../resources/alanine_ref_1.pdb'],
    ['../resources/1l2y.pdb', '../resources/Trp_cage_ref_1.pdb'] if not CONFIG_71 else ['../resources/1l2y.pdb', '../resources/1l2y.pdb'], # mixed_err
    # ['../resources/2src.pdb', '../resources/2src.pdb']
    ['../resources/2src.pdb'],
    ['../resources/BetaHairpin.pdb']
])                   # list of reference file
CONFIG_63 = get_mol_param([
    ['', '_1'],
    ['', '_1'],
    [''], ['']
    ]
)                         # suffix for each reference configuration
CONFIG_61 = ['_aligned%s_coordinates.txt' % item
             for item in CONFIG_63]  # alignment_coor_file_suffix_list (we use different suffix for aligned files with respect to different references)
CONFIG_64 = get_mol_param([
    ['backbone', 'backbone'],
    ['backbone', 'backbone'] if not CONFIG_71 else ['backbone and resid 2:8', 'backbone'], # mixed_err
    # ['backbone and resid 144:170', 'backbone and resid 44:58']
    ['backbone'],
    ['backbone']
    ])                             # atom selection statement list for structural alignment
CONFIG_55 = len(CONFIG_61)                  # number of reference configurations used in training

if CONFIG_76 == 'cossin':
    CONFIG_3 = get_mol_param([
         [8, 15, CONFIG_37, 15, 8],  # the structure of ANN: number of nodes in each layer
         [76, 50, CONFIG_37, 50, 76]
        ])
    # raise Exception("Warning: it is not a good idea to use cossin as inputs!  " + WARNING_INFO)
elif CONFIG_76 == 'Cartesian':
    CONFIG_3 = get_mol_param([
         [3 * len(CONFIG_57[0]), 40, CONFIG_37, 40, 3 * len(CONFIG_57[0]) * CONFIG_55],  
         [3 * len(CONFIG_57[1]), 50, CONFIG_37, 50, 3 * len(CONFIG_57[1]) * CONFIG_55] if not CONFIG_71 else [3 * len(CONFIG_57[1]), 50, CONFIG_37, 50, 243], # mixed_err
         # [3 * len(CONFIG_57[2]), 100, CONFIG_37, 100, 42 * 9],
        [3 * len(CONFIG_57[2]), 100, CONFIG_37, 100, 3 * len(CONFIG_57[2])],
        [3 * len(CONFIG_57[3]), 100, CONFIG_37, 100, 3 * len(CONFIG_57[3])],
         ])  # the structure of ANN: number of nodes in each
elif CONFIG_76 == 'pairwise_distance':
    CONFIG_3 = get_mol_param([
        None,
        [3 * len(CONFIG_57[1]), 50, CONFIG_37, 50, 1770],
        None, None
    ])
elif CONFIG_76 == 'combined':
    CONFIG_3 = get_mol_param([
        None,
        [3 * len(CONFIG_57[1]), 50, CONFIG_37, 50, 243 + 20 * 19 / 2],
        None, None
    ])
else:
    raise Exception('error output data type')

CONFIG_74 = False                  # whether we start each biased simulation with nearest configuration or a fixed configuration
CONFIG_40 = 'implicit'                  # whether to include water molecules, option: explicit, implicit, water_already_included, no_water
CONFIG_51 = 'NPT'                  # simulation ensemble type (for Trp-cage only)
CONFIG_42 = False                             # whether to enable force constant adjustable mode
CONFIG_44 = False                             # whether to use hierarchical autoencoder
CONFIG_77 = 2                      # hierarchical autoencoder variant index
# if CONFIG_44:
#     raise Exception("Warning: no longer supported (used for backward compatibility)!  " + WARNING_INFO)
CONFIG_46 = False                             # whether to enable verbose mode (print training status)
CONFIG_47 = False                        # whether to set the output layer as circular layer
if CONFIG_47:
    raise Exception("Warning: this is a bad choice!  " + WARNING_INFO)

CONFIG_13 = get_mol_param([3,3, 3, 3])  # num of network trainings we are going to run, and pick the one with least FVE from them
CONFIG_43 = False    # whether we need to parallelize training part, not recommended for single-core computers
if CONFIG_43:
    raise Exception("Warning: parallelization of training is not well tested!  " + WARNING_INFO)

CONFIG_31 = 10        # maximum number of failed simulations allowed in each iteration

CONFIG_56 = get_mol_param([20, 8, 6, 6])    # number of biased simulations running in parallel
CONFIG_14 = 6  # max number of jobs submitted each time
CONFIG_29 = True  if CONFIG_40 == 'explicit' else False   # whether we need to remove the water molecules from pdb files
CONFIG_50 = False   # whether we need to preserve original file if water molecules are removed

CONFIG_10 = get_mol_param([10,10, 10, 10])   # num of bins for get_boundary_points()
CONFIG_11 = get_mol_param([15,20, 15, 15])  # num of boundary points

CONFIG_39 = False    #  set the range of histogram automatically based on min,max values in each dimension
CONFIG_41 = False    # whether we reverse the order of sorting of diff_with_neighbors values in get_boundary algorithm

if CONFIG_17[1] == CircularLayer:
    CONFIG_18 = True  # whether we limit the boundary points to be between [-pi, pi], typically works for circularLayer
    CONFIG_26 = [[-np.pi, np.pi] for item in range(CONFIG_36)]    # range of PCs, for circular case, it is typically [[-np.pi, np.pi],[-np.pi, np.pi]]
elif CONFIG_17[1] == TanhLayer:
    CONFIG_18 = False
    CONFIG_26 = [[-1, 1] for item in range(CONFIG_36)]
elif CONFIG_17[1] == ReluLayer:
    CONFIG_18 = False
    CONFIG_26 = [[-1, 1] for item in range(CONFIG_36)]
    raise Exception("Warning: very few tests are done for ReLu layer, this is not recommended!  " + WARNING_INFO)
else:
    raise Exception('Layer not defined')

CONFIG_33 = CONFIG_3[0]   # length of list of cos/sin values, equal to the number of nodes in input layer
CONFIG_12 = '../target/' + CONFIG_30  # folder that contains all pdb files

CONFIG_65 = "US"          # default biasing method
CONFIG_16 = get_mol_param([500, 5000, 2000, 2000])                     # record interval (the frequency of writing system state into the file)
CONFIG_8 = get_mol_param([50000, 500000, 200000, 200000])                  # num of simulation steps
CONFIG_72 = 0             # enable fast equilibration
# following: for umbrella sampling
CONFIG_9 = get_mol_param([3000, 2000, 3000, 3000])                     # force constant for biased simulations
CONFIG_53 = get_mol_param(['fixed', 'fixed', 'fixed', 'fixed'])          # use fixed/flexible force constants for biased simulation for each iteration
CONFIG_54 = 2.50 * get_mol_param([30.0, 20.0, 15.0, 20.0])             # max external potential energy allowed (in k_BT)
# following: for metadynamics
CONFIG_66 = get_mol_param([500, 500, 500, None])          # pace of metadynamics
CONFIG_67 = get_mol_param([2, 2, 2, None])              # height of metadynamics
CONFIG_68 = get_mol_param([0.1, 0.1, 0.1, None])          # sigma of metadynamics
CONFIG_69 = get_mol_param([0, 0, 0, None])             # whether to use well-tempered version
CONFIG_70 = get_mol_param([15, 15, 15, None])           # biasfactor for well-tempered metadynamics
CONFIG_19 = '48:00:00'                                    # max running time for the sge job

CONFIG_21 = 300   # simulation temperature
CONFIG_22 = 0.002   # simulation time step, in ps

CONFIG_23 = get_mol_param(['CPU', 'CUDA', 'CUDA', 'CUDA'])              # simulation platform

temp_home_directory = subprocess.check_output('echo $HOME', shell=True).strip()
if temp_home_directory == "/home/fisiksnju" or temp_home_directory == "/home/kengyangyao":
    CONFIG_24 = 'local'  # machine to run the simulations
    CONFIG_25 = temp_home_directory + '/.anaconda2/lib/plugins'  # this is the directory where the plugin is installed
elif temp_home_directory == "/home/weichen9":
    CONFIG_24 = 'cluster'  # machine to run the simulations
    CONFIG_25 = '/home/weichen9/.my_softwares/openmm7/lib/plugins'
else:
    print ('unknown user directory: %s' % temp_home_directory)

# if CONFIG_24 == "cluster":
#     raise Exception("Warning: it has not been tested on the cluster for relatively long time, not recommended!  " + WARNING_INFO)

CONFIG_27 =  map(lambda x: layer_type_to_name_mapping[x], CONFIG_17[:2]) # layer_types for ANN_Force, it should be consistent with autoencoder
CONFIG_28 = "ANN_Force"    # the mode of biased force, it could be either "CustomManyParticleForce" (provided in the package) or "ANN_Force" (I wrote)

CONFIG_32 = 5000           # maximum force constant allowed (for force constant adjustable mode)
CONFIG_34 = 500            # force constant step, the value by which the force constant is increased each time (for force constant adjustable mode)
CONFIG_35 = 0.1            # distance tolerance, max distance allowed between center of data cloud and potential center (for force_constant_adjustable mode)
